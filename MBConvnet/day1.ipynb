{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c69372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b46063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class MBConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size,\n",
    "                 stride:int,\n",
    "                 expansion_factor:int):\n",
    "        super(MBConvBlock, self).__init__()\n",
    "        \n",
    "        # logic check : We only skip connect if tje shape matches\n",
    "        # 1. stride must be 1 (so the spacial dimensions match)\n",
    "        # 2. Input channels must equal output channels\n",
    "        \n",
    "        self.use_residual = (stride == 1 and in_channels == out_channels)\n",
    "        \n",
    "        # calculate the 'Wide' Inner dimensions (hidden dimension)\n",
    "        # if the input is 32 and the expansion is 6 then the hidden dimension is 32 * 6 = 192\n",
    "        hidden_dim = int(in_channels * expansion_factor)\n",
    "        \n",
    "        # we will wrap the layers in the list and wrap them later\n",
    "        layers = []\n",
    "        \n",
    "        #phase1\n",
    "        # The expansion Phase (Narrow - wide)\n",
    "        # If the expansion factor is greater than 1 , we need the 1x1 conv to blow up the channels, If expansions is 1 ( like in the very first layer of MobileNet) , we skip this step entirely\n",
    "        \n",
    "        if expansion_factor != 1:\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=hidden_dim, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(num_features=hidden_dim),\n",
    "                nn.ReLU6(inplace=True) # ReLU6 is standard for all the mobile nets\n",
    "            ])\n",
    "        #phase 2\n",
    "        # Depth wise Convolution\n",
    "        # This is the most critical part, we use the groups = hidden_dim. this forces the network to learn a separate filter for every single channel , rather than mixing them all together.\n",
    "        # this is where the efficiency comes from\n",
    "        \n",
    "        # 3x3 conv (usually) handling spatial patterns \n",
    "        layers.extend([\n",
    "            #groups= hidden_dim is the magic argument here\n",
    "            nn.Conv2d(in_channels=hidden_dim,\n",
    "                      out_channels=hidden_dim,\n",
    "                      kernel_size=kernel_size,\n",
    "                      stride=stride,\n",
    "                      padding= kernel_size//2,\n",
    "                      groups=hidden_dim,\n",
    "                      bias = False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        ])\n",
    "        \n",
    "        #Why we did this: padding=kernel_size//2 ensures that if stride=1, the output size remains exactly the same as input size. bias=False is used because BatchNorm essentially negates the bias anyway.\n",
    "        \n",
    "        # phase 3\n",
    "        # The projection phase (wide -> Narrow)\n",
    "        # the 'linear bottleneck '. We squash the channels back to the out_channels \n",
    "        # CRUCIALLY we do not add the actication function (layer) at the end\n",
    "        \n",
    "        # 1x1 conv to reduce the channels back to output size\n",
    "        \n",
    "        layers.extend([\n",
    "            nn.Conv2d(in_channels=hidden_dim,\n",
    "                      out_channels=out_channels,\n",
    "                      kernel_size=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "            # STOP! Do not add ReLU here. This is the \"Linear Bottleneck\".\n",
    "        ])\n",
    "        \n",
    "        #convert the layer into sequential\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        #Why we did this: Adding ReLU here would destroy the information we just compressed. We keep it linear to preserve the \"manifold of interest.\"\n",
    "        \n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        if self.use_residual:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "        \n",
    "\n",
    "block = MBConvBlock(in_channels=32,\n",
    "                    out_channels=32,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    expansion_factor=6)\n",
    "\n",
    "x = torch.randn(1, 32, 64, 64)\n",
    "\n",
    "out = block(x)\n",
    "\n",
    "print(out.shape)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9336f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "block = MBConvBlock(in_channels=32,\n",
    "                    out_channels=32,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    expansion_factor=0.5)\n",
    "\n",
    "x = torch.randn(1, 32, 64, 64)\n",
    "\n",
    "out = block(x)\n",
    "\n",
    "print(out.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc843d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 32, 64, 64])\n",
      "Output: torch.Size([1, 64, 32, 32])\n",
      "SUCCESS: Downsampling handled correctly, residual skipped.\n"
     ]
    }
   ],
   "source": [
    "class MBConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size,\n",
    "                 stride:int,\n",
    "                 expansion_factor:int):\n",
    "        super(MBConvBlock, self).__init__()\n",
    "        \n",
    "        # logic check : We only skip connect if tje shape matches\n",
    "        # 1. stride must be 1 (so the spacial dimensions match)\n",
    "        # 2. Input channels must equal output channels\n",
    "        \n",
    "        self.use_residual = (stride == 1 and in_channels == out_channels)\n",
    "        \n",
    "        if stride == 2:\n",
    "            self.use_residual = False\n",
    "        \n",
    "        \n",
    "        # calculate the 'Wide' Inner dimensions (hidden dimension)\n",
    "        # if the input is 32 and the expansion is 6 then the hidden dimension is 32 * 6 = 192\n",
    "        hidden_dim = int(in_channels * expansion_factor)\n",
    "        \n",
    "        # we will wrap the layers in the list and wrap them later\n",
    "        layers = []\n",
    "        \n",
    "        #phase1\n",
    "        # The expansion Phase (Narrow - wide)\n",
    "        # If the expansion factor is greater than 1 , we need the 1x1 conv to blow up the channels, If expansions is 1 ( like in the very first layer of MobileNet) , we skip this step entirely\n",
    "        \n",
    "        if expansion_factor != 1:\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=hidden_dim, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(num_features=hidden_dim),\n",
    "                nn.ReLU6(inplace=True) # ReLU6 is standard for all the mobile nets\n",
    "            ])\n",
    "        #phase 2\n",
    "        # Depth wise Convolution\n",
    "        # This is the most critical part, we use the groups = hidden_dim. this forces the network to learn a separate filter for every single channel , rather than mixing them all together.\n",
    "        # this is where the efficiency comes from\n",
    "        \n",
    "        # 3x3 conv (usually) handling spatial patterns \n",
    "        layers.extend([\n",
    "            #groups= hidden_dim is the magic argument here\n",
    "            nn.Conv2d(in_channels=hidden_dim,\n",
    "                      out_channels=hidden_dim,\n",
    "                      kernel_size=kernel_size,\n",
    "                      stride=stride,\n",
    "                      padding= kernel_size//2,\n",
    "                      groups=hidden_dim,\n",
    "                      bias = False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        ])\n",
    "        \n",
    "        #Why we did this: padding=kernel_size//2 ensures that if stride=1, the output size remains exactly the same as input size. bias=False is used because BatchNorm essentially negates the bias anyway.\n",
    "        \n",
    "        # phase 3\n",
    "        # The projection phase (wide -> Narrow)\n",
    "        # the 'linear bottleneck '. We squash the channels back to the out_channels \n",
    "        # CRUCIALLY we do not add the actication function (layer) at the end\n",
    "        \n",
    "        # 1x1 conv to reduce the channels back to output size\n",
    "        \n",
    "        layers.extend([\n",
    "            nn.Conv2d(in_channels=hidden_dim,\n",
    "                      out_channels=out_channels,\n",
    "                      kernel_size=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "            # STOP! Do not add ReLU here. This is the \"Linear Bottleneck\".\n",
    "        ])\n",
    "        \n",
    "        #convert the layer into sequential\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        #Why we did this: Adding ReLU here would destroy the information we just compressed. We keep it linear to preserve the \"manifold of interest.\"\n",
    "        \n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        if self.use_residual:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "        \n",
    "\n",
    "# Scenario: Transitioning from 32 channels to 64 channels, and shrinking image size\n",
    "block_downsample = MBConvBlock(in_channels=32, out_channels=64, kernel_size=3, stride=2, expansion_factor=6)\n",
    "\n",
    "x = torch.randn(1, 32, 64, 64)\n",
    "out = block_downsample(x)\n",
    "\n",
    "print(f\"Input: {x.shape}\")\n",
    "print(f\"Output: {out.shape}\")\n",
    "\n",
    "if x.shape[2] // 2 == out.shape[2]:\n",
    "    print(\"SUCCESS: Downsampling handled correctly, residual skipped.\")\n",
    "else:\n",
    "    print(\"FAILURE: Dimensions mismatch.\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2152b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000, width_mult=1.0):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        # 1. Configuration\n",
    "        # t, c, n, s  t -> expansion_factor, c -> out_channels, n -> number of times to repeat the block, s -> stride\n",
    "\n",
    "        self.config = [\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # 2. STEM (Initial Processing)\n",
    "        # standard 3x3 Conv to get the thing started\n",
    "\n",
    "        input_channel = 32\n",
    "        last_channel = 1280  # standard first expansion\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=input_channel,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(input_channel),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "        # 3. The Body (stacking the MBConvBlocks)\n",
    "        layers = []\n",
    "        for t, c, n, s in self.config:\n",
    "            for i in range(n):\n",
    "\n",
    "                # CRITICAL LOGIC:\n",
    "                # ONLY the first block in a sequence uses the defined stride\n",
    "                # All subsequent blocks must utilzie stride 1\n",
    "                stride = s if i == 0 else 1\n",
    "\n",
    "                layers.append(\n",
    "                    MBConvBlock(\n",
    "                        in_channels=input_channel,\n",
    "                        out_channels=c,\n",
    "                        kernel_size=3,\n",
    "                        stride=stride,\n",
    "                        expansion_factor=t,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # update the input channel for the next iteration\n",
    "                input_channel = c\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        # 4. The HEAD (classifiacation)\n",
    "        # Expand features to 1280 -> Global Avg Pool -> classifier\n",
    "\n",
    "        self.conv_last = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channel,\n",
    "                out_channels=last_channel,\n",
    "                kernel_size=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(last_channel),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=last_channel, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 1. STEM\n",
    "        x = self.stem(x)\n",
    "\n",
    "        # 2. Body\n",
    "        x = self.features(x)\n",
    "\n",
    "        # 3. Head\n",
    "        x = self.conv_last(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6893911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 3.50 Million\n",
      "Input: torch.Size([1, 3, 224, 224])\n",
      "Output: torch.Size([1, 1000])\n",
      "✅ ARCHITECTURE COMPLETED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate\n",
    "model = MobileNetV2(num_classes=1000)\n",
    "\n",
    "# 2. Count Parameters (Should be approx 3.5 Million)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Parameters: {total_params/1e6:.2f} Million\")\n",
    "\n",
    "# 3. Pass Data\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(f\"Input: {dummy_input.shape}\")\n",
    "print(f\"Output: {output.shape}\")\n",
    "\n",
    "# 4. Final Sanity Check\n",
    "if output.shape == (1, 1000):\n",
    "    print(\"✅ ARCHITECTURE COMPLETED SUCCESSFULLY\")\n",
    "else:\n",
    "    print(\"❌ DIMENSION ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8bbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
